¿Alguna vez abriste una red social y sentiste que ya no es tuya, como si entraras a tu propia casa y estuviera llena de extraños gritando?
Sí, totalmente. Se siente como un lugar lleno de ruido, de gente que actúa para un algoritmo, para una cámara que ni siquiera vemos.
Exacto. Y usarla para lo que se supone que era, o sea, conectar con gente, descubrir cosas, se ha vuelto casi imposible.
Y fíjate que esa sensación no es una paranoia tuya. Es real. Justo tenemos en nuestras manos una serie de documentos, todos de enero de 2026, que argumentan que esto no es un accidente.
Ah, no es un fallo del sistema.
No. Es el sistema funcionando a la perfección, tal como fue diseñado. El problema es que el diseño está fundamentalmente roto. Es como querer tener una conversación profunda en medio de una discoteca. Simplemente las herramientas no sirven para eso.
Claro. Y aquí es donde uno de los textos menciona la ley de Goodhart, que me encantó. Dice algo como que cuando una medida se convierte en un objetivo, deja de ser una buena medida.
Ajá. Exactamente. Los me gusta, los seguidores, se suponía que eran un reflejo de que algo era interesante.
Pero se convirtieron en la meta, en el juego a ganar.
Y en ese momento perdieron todo su significado. Ahora son solo puntos en una máquina.
Y ese es el punto de partida de nuestra conversación de hoy. Vamos a seguir ese hilo, el de la frustración con nuestro feed caótico, para ver cómo estos documentos lo conectan con algo muchísimo más grande.
Con el futuro de la gobernanza de la inteligencia artificial. La tesis es audaz. Dice que la misma falla arquitectónica que arruinó nuestras redes sociales es la que nos podría llevar a un futuro catastrófico con la IA.
Así que, esa es nuestra misión. Vamos a desentrañar esa conexión. Entender por qué nuestros espacios digitales se sienten rotos y explorar una solución arquitectónica que, según estos textos, no solo puede arreglarlos.
Sino que puede guiarnos por lo que llaman un camino estrecho, un corredor seguro entre dos futuros terribles, dominación por una IA o el caos absoluto de muchas IAs compitiendo.
Suena a ciencia ficción, pero la propuesta es muy, muy concreta. Bueno, empecemos por el diagnóstico.
De acuerdo. Si la D de Good Heart es el veneno, ¿cómo vemos los síntomas?
Los textos dicen que cuando el engagement es el rey, todo lo demás fracasa. Buscar pareja, encontrar colaboradores, tener una discusión seria. Fracasa porque el sistema incentiva una cosa, la actuación.
La identidad deja de ser una expresión tuya y se convierte en una actuación para el algoritmo.
Claro.
Optimizada para la reacción inmediata.
Exacto. Los perfiles no buscan representar a una persona. Buscan provocar. Curiosidad, indignación, sorpresa. Un me gusta ya no significa me atraes.
Significa, mi cerebro respondió a este estímulo. Se vacía por completo el significado.
Por completo. Y esto, dicen, no es un problema de comportamiento. Es de arquitectura.
Ahí mencionan algo que llaman el átomo ordenado por el FID. ¿A qué se refieren con eso?
Ese es el corazón técnico del problema. Significa que la unidad más básica, el átomo de estas plataformas, es la publicación individual, el post.
Cada uno por su cuenta.
Sí. Cada post es una entidad única, aislada, sin conexión real con nada más. Y esto tiene consecuencias muy extrañas.
A ver, dame un ejemplo concreto. Los documentos usan uno que es brillante, el dilema de la foto de portada. Imagínate que subes una foto nueva a tu perfil.
Ok.
Y luego haces una publicación con esa misma foto para que tus amigos la vean. Para cualquier persona, es el mismo objeto, mi foto nueva.
Claro, es la misma foto.
Pero para la plataforma, son dos cosas completamente distintas. La foto de portada es una cosa y la publicación es otra. Los me gusta y comentarios se fragmentan.
Espera. ¿En serio? O sea que, ¿no existe el concepto de esta foto como un objeto central? ¿Son solo copias?
Eso es. ¡Absurdo!
Es absurdo. Pero es la base de todo. El sistema no tiene memoria de identidad de los objetos. Solo un río de eventos aislados. Y esto significa que es estructuralmente imposible acumular significado.
La identidad de las personas y de las ideas se disuelve.
La fragmentación la recompensa. Porque cada copia es una nueva oportunidad de generar engagement. La dispersión es el objetivo.
Bueno, el diagnóstico es desolador. Son máquinas de fragmentar el significado. Si el problema es tan arquitectónico, la solución tiene que serlo también.
Y aquí los textos dan un giro hacia la filosofía, con la hipótesis del pensamiento independiente del sustrato, o SID.
Sí. Es un salto, pero es clave. La pregunta que plantea SID es, ¿y si la vida, en un sentido más fundamental, es un patrón de organización de la información que logra resistir al desorden, a la entropía?
A ver si entiendo. ¿Me estás diciendo que un conjunto de leyes o una teoría científica podría considerarse vivo?
Bajo esta hipótesis, sí. Cualquier sistema de información que se mantiene a sí mismo, de forma recursiva, o sea, que usa sus propias reglas para preservarse y replicarse, exhibe las características de la vida.
Se reproduce, muta.
Y puede morir. Y aquí viene el concepto clave. Muere cuando cruza el umbral de error semántico.
Umbral de error semántico. Suena…
Denso.
Piensa en el juego del teléfono descompuesto. El mensaje inicial está vivo, mientras se transmite. Muta un poco, pero se reconoce.
El umbral es el punto en que el mensaje se distorsiona tanto que ya no tiene nada que ver con el original.
Ah, claro. En ese momento, la idea original murió.
Exacto. Ya nos está replicando. Todos los sistemas de información vivos luchan contra ese umbral de error.
Ahora lo entiendo. ¿Y nuestras redes sociales, con su arquitectura fragmentada?
Son aceleradores de error semántico.
Son entornos hostiles para la vida de la información.
Precisamente. Y para aterrizar esto, uno de los textos usa un ejemplo genial y súper simple. Un archivador. Un archivador de oficina.
Un mueble.
Sí. Un archivador no es solo un mueble. Es una tecnología. Es lo que llaman un operador semántico.
¿Qué hace? Impone un orden. Crea categorías.
Separa los documentos. Evita que se mezclen.
Exacto. Reduce la entropía y al hacerlo estabiliza el significado de lo que contiene.
Es una prueba física de que no podemos tener pensamiento coherente si no le damos una estructura, un mueble, que lo contenga.
Vaya. O sea que nuestras ideas en redes sociales están flotando en un huracán en lugar de estar en cajones ordenados.
De ahí viene esa frase tan potente. El pensamiento sobrevive convirtiéndose en arquitectura.
Esa es la conclusión.
Para que el significado perdure, necesita un hogar.
Y si nuestros hogares digitales actuales son puro caos, pues hay que construir unos nuevos.
De acuerdo. Entonces, si necesitamos una nueva arquitectura, un nuevo mueble digital, ¿cuál es?
Aquí es donde presentan este concepto de Sphere Pop.
Te confieso que me costó entenderlo.
Dicen que en vez de estados que cambian, todo es una historia de eventos irreversibles.
Claro. A ver, la mayoría del software que usamos hoy es como un pizarón blanco.
Escribes, borras, escribes encima. Solo importa el estado actual.
No hay registro de lo que había antes.
Exacto. Sphere Pop dice que esa es una pésima manera de construir sistemas.
Propone un modelo más parecido a un libro de contabilidad.
Cada entrada es un evento nuevo que se añade al final.
No borras nada. Si te equivocas, añades una corrección.
La historia siempre está ahí.
Entiendo lo del libro de contabilidad, pero ¿qué tiene que ver con la computación?
¿Y por qué se llama Sphere Pop?
El nombre viene de una analogía matemática.
Piensa en la expresión 1 plus 2 por 3.
Primero resuelvas el paréntesis, la esfera.
Calculas 1 plus 2, queda 3.
En ese momento, el paréntesis explota, pops, y es reemplazado por su resultado.
Y te queda 3 por 3.
Claro. El punto clave es que la operación 1 más 2 es un hecho consumado.
Es un evento irreversible en la historia del cálculo.
Ya no puedes volver atrás.
Sphere Pop generaliza esa idea.
Cada acción es un compromiso que altera para siempre el futuro.
Ok. Creo que lo voy entendiendo.
Pero la palabra irreversible suena un poco intimidante.
Significa que si publico una tontería, no la puedo borrar.
Esa es la reacción natural.
Pero es una confusión importante.
Irreversible no significa que no puedas cambiar de opinión.
Ah, no.
No. De hecho, es lo contrario.
En un sistema actual, si editas un comentario, el original desaparece sin dejar rastro.
Como si nunca hubiera existido.
En Sphere Pop, la edición sería un evento nuevo que dice, el comentario anterior ahora se sustituye por este.
El historial completo es transparente.
Borrar algo es añadir el evento.
Esto fue borrado.
Le da al sistema una memoria y una responsabilidad que no tiene.
Ah, de acuerdo.
La historia se preserva.
Y esto me lleva a la solución de el camino estrecho.
La base de todo es Sphere Popo S.
¿Cómo arregla esto concretamente el problema del consentimiento?
Lo arregla porque el consentimiento deja de ser una casilla que marcas en una página de configuración.
Que un algoritmo puede ignorar o un diseñador puede esconder.
Exacto.
Se convierte en un evento histórico inmutable.
Cuando dices, no quiero ver contenido de esta categoría, esa declaración no es una preferencia.
Es un hecho consumado que se graba en la historia del sistema.
Y condiciona todo lo que viene después.
Sí.
Y la única forma de cambiarlo es emitiendo un nuevo evento que anule el anterior.
Esto tiene dos consecuencias enormes.
Se acaba la fatiga del consentimiento.
Eso de estar bloqueando cosas todo el tiempo.
Y se previene la manipulación algorítmica.
Me convence.
Honestamente, esto ya suena increíble para arreglar el caos de mi feed.
Pero aquí los documentos dan el salto gigantesco.
Pasan de esto a presentarlo como la clave para la gobernanza global de la IA.
Me parece un salto ambicioso, ¿no?
¿Cómo conectamos un timeline ordenado con salvar al mundo?
El salto es enorme, sí.
Pero la lógica es directa.
La idea es que la misma arquitectura que te da control sobre tu espacio puede escalar para dar a la sociedad control sobre agentes mucho más poderosos, como las IA's.
Y ahí es donde entran las otras dos capas.
Ahí es donde entran Polisan y Plenum Hub.
Vamos por partes.
¿Qué es Polisan?
Polisan es la capa de acciones que portan pruebas.
La idea es genial.
Una IA puede proponer cualquier acción.
Publicará algo, modificar un sistema.
Pero esa acción solo se admite si viene con una prueba matemática.
Verificable de que cumple con todas las reglas.
¿Una prueba matemática?
¿Esto no haría todo lentísimo?
Ah, ahí está la clave.
El punto es que verificar una prueba es exponencialmente más barato y rápido que crearla.
Como un Sudoku.
Exacto.
Resolverlo es difícil, pero verificar la solución es instantáneo.
Polisan obliga a la IA a hacer todo el trabajo pesado de probar que sigue las reglas.
A nosotros o a nuestros sistemas de supervisión solo nos toca hacer la verificación fácil.
Vaya.
Eso invierte la dinámica por completo.
La IA no puede actuar hasta que no demuestre que lo hace de forma segura.
Exacto.
La supervisión se vuelve escalable.
Y luego está la capa final.
Plenum Hub.
Es el tejido que coordina a múltiples sillas.
Un espacio compartido donde las reglas de todos son públicas.
Y una interacción solo se permite si satisface las reglas de todos los implicados a la vez.
A ver, eso suena a que se podría paralizar todo, ¿no?
Si cada acción tiene que satisfacer las reglas de todo el mundo.
Es una duda legítima, pero piensa en una analogía.
El control del tráfico aéreo.
Es un sistema donde cada avión debe seguir reglas estrictas, visibles para todos, para evitar chocar.
Esas reglas no paralizan los viajes.
Al contrario, son las que los hacen posibles.
Son las que los hacen posibles y seguros a gran escala.
Plenum Hub es una versión generalizada de eso.
No impide la acción, sino que previene la tragedia de los comunes,
donde todos terminan destruyendo un recurso compartido.
Aquí, las externalidades negativas están prohibidas por la arquitectura.
Entonces, para unir las piezas, SpherePop o S es la base con memoria.
Polisán es el guardián que exige pruebas y Plenum Hub es la plaza pública donde las IAs interactúan de forma segura.
Esa es la visión completa.
Y por eso lo llaman el camino estrecho.
No es un equilibrio frágil que dependa de que las IAs se porten bien.
Es un camino pavimentado, construido por diseño, que nos protege de la dominación de una IA o del caos de muchas.
Un plan de ingeniería para la gobernanza global de la IA.
El hilo conductor, si entendí bien, es que los problemas de nuestro mundo digital no son de contenido.
Son estructurales.
Son producto de una optimización sin límites.
Y ese es el mensaje final más potente.
La solución no está en moderar más o en tener mejores intenciones.
Tampoco en ir más despacio.
Está en construir sistemas con límites en su arquitectura.
El gran objetivo del alineamiento no debería ser enseñarle a las máquinas qué desear.
Sino…
Sino asegurar que ningún sistema, por inteligente que sea,
pueda anular las condiciones que hacen que la elección humana siga siendo significativa.
Hay una frase que citamos antes y que se me quedó grabada.
El pensamiento sobrevive convirtiéndose en arquitectura.
Los textos dicen que nuestros entornos, desde un archivador a una ciudad, extienden nuestra mente.
Y esto me deja con una última reflexión.
Quizás lo más importante que construiremos este siglo no sea una IA más inteligente.
Sino…
Sino una habitación más sabia para que esa inteligencia pueda vivir.
