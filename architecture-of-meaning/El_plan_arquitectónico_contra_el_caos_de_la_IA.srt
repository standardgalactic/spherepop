1
00:00:00,000 --> 00:00:10,380
¿Alguna vez abriste una red social y sentiste que ya no es tuya, como si entraras a tu propia casa y estuviera llena de extraños gritando?

2
00:00:10,700 --> 00:00:20,060
Sí, totalmente. Se siente como un lugar lleno de ruido, de gente que actúa para un algoritmo, para una cámara que ni siquiera vemos.

3
00:00:20,560 --> 00:00:28,840
Exacto. Y usarla para lo que se supone que era, o sea, conectar con gente, descubrir cosas, se ha vuelto casi imposible.

4
00:00:28,840 --> 00:00:42,920
Y fíjate que esa sensación no es una paranoia tuya. Es real. Justo tenemos en nuestras manos una serie de documentos, todos de enero de 2026, que argumentan que esto no es un accidente.

5
00:00:43,340 --> 00:00:45,780
Ah, no es un fallo del sistema.

6
00:00:45,780 --> 00:01:02,020
No. Es el sistema funcionando a la perfección, tal como fue diseñado. El problema es que el diseño está fundamentalmente roto. Es como querer tener una conversación profunda en medio de una discoteca. Simplemente las herramientas no sirven para eso.

7
00:01:02,020 --> 00:01:15,420
Claro. Y aquí es donde uno de los textos menciona la ley de Goodhart, que me encantó. Dice algo como que cuando una medida se convierte en un objetivo, deja de ser una buena medida.

8
00:01:15,920 --> 00:01:23,140
Ajá. Exactamente. Los me gusta, los seguidores, se suponía que eran un reflejo de que algo era interesante.

9
00:01:23,140 --> 00:01:26,640
Pero se convirtieron en la meta, en el juego a ganar.

10
00:01:26,680 --> 00:01:31,560
Y en ese momento perdieron todo su significado. Ahora son solo puntos en una máquina.

11
00:01:31,980 --> 00:01:44,340
Y ese es el punto de partida de nuestra conversación de hoy. Vamos a seguir ese hilo, el de la frustración con nuestro feed caótico, para ver cómo estos documentos lo conectan con algo muchísimo más grande.

12
00:01:44,340 --> 00:01:57,460
Con el futuro de la gobernanza de la inteligencia artificial. La tesis es audaz. Dice que la misma falla arquitectónica que arruinó nuestras redes sociales es la que nos podría llevar a un futuro catastrófico con la IA.

13
00:01:57,460 --> 00:02:14,400
Así que, esa es nuestra misión. Vamos a desentrañar esa conexión. Entender por qué nuestros espacios digitales se sienten rotos y explorar una solución arquitectónica que, según estos textos, no solo puede arreglarlos.

14
00:02:14,400 --> 00:02:27,040
Sino que puede guiarnos por lo que llaman un camino estrecho, un corredor seguro entre dos futuros terribles, dominación por una IA o el caos absoluto de muchas IAs compitiendo.

15
00:02:27,460 --> 00:02:34,080
Suena a ciencia ficción, pero la propuesta es muy, muy concreta. Bueno, empecemos por el diagnóstico.

16
00:02:34,400 --> 00:02:39,660
De acuerdo. Si la D de Good Heart es el veneno, ¿cómo vemos los síntomas?

17
00:02:39,800 --> 00:02:55,660
Los textos dicen que cuando el engagement es el rey, todo lo demás fracasa. Buscar pareja, encontrar colaboradores, tener una discusión seria. Fracasa porque el sistema incentiva una cosa, la actuación.

18
00:02:55,660 --> 00:03:02,660
La identidad deja de ser una expresión tuya y se convierte en una actuación para el algoritmo.

19
00:03:03,640 --> 00:03:04,040
Claro.

20
00:03:04,660 --> 00:03:07,160
Optimizada para la reacción inmediata.

21
00:03:07,460 --> 00:03:19,360
Exacto. Los perfiles no buscan representar a una persona. Buscan provocar. Curiosidad, indignación, sorpresa. Un me gusta ya no significa me atraes.

22
00:03:19,360 --> 00:03:26,560
Significa, mi cerebro respondió a este estímulo. Se vacía por completo el significado.

23
00:03:26,860 --> 00:03:32,620
Por completo. Y esto, dicen, no es un problema de comportamiento. Es de arquitectura.

24
00:03:32,740 --> 00:03:38,740
Ahí mencionan algo que llaman el átomo ordenado por el FID. ¿A qué se refieren con eso?

25
00:03:38,740 --> 00:03:49,420
Ese es el corazón técnico del problema. Significa que la unidad más básica, el átomo de estas plataformas, es la publicación individual, el post.

26
00:03:49,580 --> 00:03:50,920
Cada uno por su cuenta.

27
00:03:51,120 --> 00:04:00,000
Sí. Cada post es una entidad única, aislada, sin conexión real con nada más. Y esto tiene consecuencias muy extrañas.

28
00:04:00,000 --> 00:04:12,220
A ver, dame un ejemplo concreto. Los documentos usan uno que es brillante, el dilema de la foto de portada. Imagínate que subes una foto nueva a tu perfil.

29
00:04:12,440 --> 00:04:12,700
Ok.

30
00:04:13,180 --> 00:04:22,960
Y luego haces una publicación con esa misma foto para que tus amigos la vean. Para cualquier persona, es el mismo objeto, mi foto nueva.

31
00:04:23,080 --> 00:04:24,360
Claro, es la misma foto.

32
00:04:24,360 --> 00:04:36,820
Pero para la plataforma, son dos cosas completamente distintas. La foto de portada es una cosa y la publicación es otra. Los me gusta y comentarios se fragmentan.

33
00:04:36,960 --> 00:04:45,400
Espera. ¿En serio? O sea que, ¿no existe el concepto de esta foto como un objeto central? ¿Son solo copias?

34
00:04:45,580 --> 00:04:48,360
Eso es. ¡Absurdo!

35
00:04:48,360 --> 00:05:03,760
Es absurdo. Pero es la base de todo. El sistema no tiene memoria de identidad de los objetos. Solo un río de eventos aislados. Y esto significa que es estructuralmente imposible acumular significado.

36
00:05:04,400 --> 00:05:08,760
La identidad de las personas y de las ideas se disuelve.

37
00:05:08,760 --> 00:05:17,680
La fragmentación la recompensa. Porque cada copia es una nueva oportunidad de generar engagement. La dispersión es el objetivo.

38
00:05:18,360 --> 00:05:29,160
Bueno, el diagnóstico es desolador. Son máquinas de fragmentar el significado. Si el problema es tan arquitectónico, la solución tiene que serlo también.

39
00:05:29,900 --> 00:05:37,020
Y aquí los textos dan un giro hacia la filosofía, con la hipótesis del pensamiento independiente del sustrato, o SID.

40
00:05:37,020 --> 00:05:52,360
Sí. Es un salto, pero es clave. La pregunta que plantea SID es, ¿y si la vida, en un sentido más fundamental, es un patrón de organización de la información que logra resistir al desorden, a la entropía?

41
00:05:52,360 --> 00:05:59,760
A ver si entiendo. ¿Me estás diciendo que un conjunto de leyes o una teoría científica podría considerarse vivo?

42
00:06:00,080 --> 00:06:13,740
Bajo esta hipótesis, sí. Cualquier sistema de información que se mantiene a sí mismo, de forma recursiva, o sea, que usa sus propias reglas para preservarse y replicarse, exhibe las características de la vida.

43
00:06:14,100 --> 00:06:16,060
Se reproduce, muta.

44
00:06:16,060 --> 00:06:22,500
Y puede morir. Y aquí viene el concepto clave. Muere cuando cruza el umbral de error semántico.

45
00:06:23,560 --> 00:06:27,020
Umbral de error semántico. Suena…

46
00:06:27,020 --> 00:06:28,140
Denso.

47
00:06:28,720 --> 00:06:36,060
Piensa en el juego del teléfono descompuesto. El mensaje inicial está vivo, mientras se transmite. Muta un poco, pero se reconoce.

48
00:06:37,100 --> 00:06:42,980
El umbral es el punto en que el mensaje se distorsiona tanto que ya no tiene nada que ver con el original.

49
00:06:42,980 --> 00:06:47,560
Ah, claro. En ese momento, la idea original murió.

50
00:06:48,220 --> 00:06:54,620
Exacto. Ya nos está replicando. Todos los sistemas de información vivos luchan contra ese umbral de error.

51
00:06:54,840 --> 00:06:59,980
Ahora lo entiendo. ¿Y nuestras redes sociales, con su arquitectura fragmentada?

52
00:07:00,980 --> 00:07:02,980
Son aceleradores de error semántico.

53
00:07:03,820 --> 00:07:08,240
Son entornos hostiles para la vida de la información.

54
00:07:08,240 --> 00:07:20,160
Precisamente. Y para aterrizar esto, uno de los textos usa un ejemplo genial y súper simple. Un archivador. Un archivador de oficina.

55
00:07:20,400 --> 00:07:20,900
Un mueble.

56
00:07:21,440 --> 00:07:29,520
Sí. Un archivador no es solo un mueble. Es una tecnología. Es lo que llaman un operador semántico.

57
00:07:29,520 --> 00:07:34,060
¿Qué hace? Impone un orden. Crea categorías.

58
00:07:34,360 --> 00:07:37,300
Separa los documentos. Evita que se mezclen.

59
00:07:37,680 --> 00:07:43,080
Exacto. Reduce la entropía y al hacerlo estabiliza el significado de lo que contiene.

60
00:07:43,740 --> 00:07:50,300
Es una prueba física de que no podemos tener pensamiento coherente si no le damos una estructura, un mueble, que lo contenga.

61
00:07:50,300 --> 00:07:57,320
Vaya. O sea que nuestras ideas en redes sociales están flotando en un huracán en lugar de estar en cajones ordenados.

62
00:07:57,800 --> 00:08:02,940
De ahí viene esa frase tan potente. El pensamiento sobrevive convirtiéndose en arquitectura.

63
00:08:03,460 --> 00:08:04,460
Esa es la conclusión.

64
00:08:05,360 --> 00:08:07,960
Para que el significado perdure, necesita un hogar.

65
00:08:08,400 --> 00:08:13,780
Y si nuestros hogares digitales actuales son puro caos, pues hay que construir unos nuevos.

66
00:08:13,780 --> 00:08:21,860
De acuerdo. Entonces, si necesitamos una nueva arquitectura, un nuevo mueble digital, ¿cuál es?

67
00:08:22,260 --> 00:08:25,360
Aquí es donde presentan este concepto de Sphere Pop.

68
00:08:25,900 --> 00:08:28,380
Te confieso que me costó entenderlo.

69
00:08:29,000 --> 00:08:34,660
Dicen que en vez de estados que cambian, todo es una historia de eventos irreversibles.

70
00:08:35,100 --> 00:08:39,860
Claro. A ver, la mayoría del software que usamos hoy es como un pizarón blanco.

71
00:08:39,860 --> 00:08:44,980
Escribes, borras, escribes encima. Solo importa el estado actual.

72
00:08:45,660 --> 00:08:47,780
No hay registro de lo que había antes.

73
00:08:48,220 --> 00:08:53,080
Exacto. Sphere Pop dice que esa es una pésima manera de construir sistemas.

74
00:08:53,780 --> 00:08:56,580
Propone un modelo más parecido a un libro de contabilidad.

75
00:08:57,280 --> 00:09:00,000
Cada entrada es un evento nuevo que se añade al final.

76
00:09:00,700 --> 00:09:03,960
No borras nada. Si te equivocas, añades una corrección.

77
00:09:04,500 --> 00:09:06,140
La historia siempre está ahí.

78
00:09:06,140 --> 00:09:10,980
Entiendo lo del libro de contabilidad, pero ¿qué tiene que ver con la computación?

79
00:09:11,640 --> 00:09:13,240
¿Y por qué se llama Sphere Pop?

80
00:09:14,160 --> 00:09:16,400
El nombre viene de una analogía matemática.

81
00:09:17,320 --> 00:09:20,260
Piensa en la expresión 1 plus 2 por 3.

82
00:09:20,860 --> 00:09:23,440
Primero resuelvas el paréntesis, la esfera.

83
00:09:24,080 --> 00:09:26,140
Calculas 1 plus 2, queda 3.

84
00:09:26,640 --> 00:09:32,400
En ese momento, el paréntesis explota, pops, y es reemplazado por su resultado.

85
00:09:32,400 --> 00:09:34,540
Y te queda 3 por 3.

86
00:09:35,120 --> 00:09:40,880
Claro. El punto clave es que la operación 1 más 2 es un hecho consumado.

87
00:09:41,280 --> 00:09:45,160
Es un evento irreversible en la historia del cálculo.

88
00:09:45,500 --> 00:09:46,780
Ya no puedes volver atrás.

89
00:09:47,500 --> 00:09:49,420
Sphere Pop generaliza esa idea.

90
00:09:50,040 --> 00:09:53,720
Cada acción es un compromiso que altera para siempre el futuro.

91
00:09:53,720 --> 00:09:57,460
Ok. Creo que lo voy entendiendo.

92
00:09:58,240 --> 00:10:02,640
Pero la palabra irreversible suena un poco intimidante.

93
00:10:03,340 --> 00:10:06,240
Significa que si publico una tontería, no la puedo borrar.

94
00:10:06,360 --> 00:10:07,620
Esa es la reacción natural.

95
00:10:07,980 --> 00:10:09,760
Pero es una confusión importante.

96
00:10:11,100 --> 00:10:14,680
Irreversible no significa que no puedas cambiar de opinión.

97
00:10:14,880 --> 00:10:15,300
Ah, no.

98
00:10:15,580 --> 00:10:17,840
No. De hecho, es lo contrario.

99
00:10:17,840 --> 00:10:28,600
En un sistema actual, si editas un comentario, el original desaparece sin dejar rastro.

100
00:10:28,840 --> 00:10:30,380
Como si nunca hubiera existido.

101
00:10:30,380 --> 00:10:37,460
En Sphere Pop, la edición sería un evento nuevo que dice, el comentario anterior ahora se sustituye por este.

102
00:10:38,080 --> 00:10:40,180
El historial completo es transparente.

103
00:10:40,860 --> 00:10:42,460
Borrar algo es añadir el evento.

104
00:10:42,900 --> 00:10:43,800
Esto fue borrado.

105
00:10:44,520 --> 00:10:47,880
Le da al sistema una memoria y una responsabilidad que no tiene.

106
00:10:48,520 --> 00:10:49,640
Ah, de acuerdo.

107
00:10:51,520 --> 00:10:53,040
La historia se preserva.

108
00:10:53,040 --> 00:10:58,360
Y esto me lleva a la solución de el camino estrecho.

109
00:10:59,340 --> 00:11:01,400
La base de todo es Sphere Popo S.

110
00:11:02,340 --> 00:11:06,320
¿Cómo arregla esto concretamente el problema del consentimiento?

111
00:11:06,720 --> 00:11:12,180
Lo arregla porque el consentimiento deja de ser una casilla que marcas en una página de configuración.

112
00:11:12,600 --> 00:11:16,700
Que un algoritmo puede ignorar o un diseñador puede esconder.

113
00:11:17,100 --> 00:11:17,740
Exacto.

114
00:11:17,740 --> 00:11:20,280
Se convierte en un evento histórico inmutable.

115
00:11:20,280 --> 00:11:26,360
Cuando dices, no quiero ver contenido de esta categoría, esa declaración no es una preferencia.

116
00:11:26,860 --> 00:11:29,940
Es un hecho consumado que se graba en la historia del sistema.

117
00:11:30,160 --> 00:11:32,500
Y condiciona todo lo que viene después.

118
00:11:32,840 --> 00:11:33,020
Sí.

119
00:11:34,220 --> 00:11:39,080
Y la única forma de cambiarlo es emitiendo un nuevo evento que anule el anterior.

120
00:11:39,960 --> 00:11:42,160
Esto tiene dos consecuencias enormes.

121
00:11:42,700 --> 00:11:44,680
Se acaba la fatiga del consentimiento.

122
00:11:44,680 --> 00:11:47,420
Eso de estar bloqueando cosas todo el tiempo.

123
00:11:47,420 --> 00:11:50,360
Y se previene la manipulación algorítmica.

124
00:11:50,880 --> 00:11:51,620
Me convence.

125
00:11:52,160 --> 00:11:55,900
Honestamente, esto ya suena increíble para arreglar el caos de mi feed.

126
00:11:56,460 --> 00:11:59,480
Pero aquí los documentos dan el salto gigantesco.

127
00:12:00,200 --> 00:12:05,600
Pasan de esto a presentarlo como la clave para la gobernanza global de la IA.

128
00:12:06,280 --> 00:12:09,220
Me parece un salto ambicioso, ¿no?

129
00:12:09,220 --> 00:12:13,920
¿Cómo conectamos un timeline ordenado con salvar al mundo?

130
00:12:14,360 --> 00:12:15,560
El salto es enorme, sí.

131
00:12:16,000 --> 00:12:17,480
Pero la lógica es directa.

132
00:12:18,100 --> 00:12:28,560
La idea es que la misma arquitectura que te da control sobre tu espacio puede escalar para dar a la sociedad control sobre agentes mucho más poderosos, como las IA's.

133
00:12:28,960 --> 00:12:31,300
Y ahí es donde entran las otras dos capas.

134
00:12:31,540 --> 00:12:34,060
Ahí es donde entran Polisan y Plenum Hub.

135
00:12:34,060 --> 00:12:35,800
Vamos por partes.

136
00:12:36,540 --> 00:12:37,820
¿Qué es Polisan?

137
00:12:38,620 --> 00:12:43,180
Polisan es la capa de acciones que portan pruebas.

138
00:12:43,900 --> 00:12:45,780
La idea es genial.

139
00:12:46,480 --> 00:12:48,880
Una IA puede proponer cualquier acción.

140
00:12:49,360 --> 00:12:51,740
Publicará algo, modificar un sistema.

141
00:12:52,420 --> 00:12:56,880
Pero esa acción solo se admite si viene con una prueba matemática.

142
00:12:57,240 --> 00:13:00,220
Verificable de que cumple con todas las reglas.

143
00:13:01,000 --> 00:13:02,680
¿Una prueba matemática?

144
00:13:02,680 --> 00:13:05,200
¿Esto no haría todo lentísimo?

145
00:13:05,720 --> 00:13:08,300
Ah, ahí está la clave.

146
00:13:08,820 --> 00:13:14,720
El punto es que verificar una prueba es exponencialmente más barato y rápido que crearla.

147
00:13:14,920 --> 00:13:15,780
Como un Sudoku.

148
00:13:16,120 --> 00:13:16,760
Exacto.

149
00:13:17,360 --> 00:13:21,560
Resolverlo es difícil, pero verificar la solución es instantáneo.

150
00:13:22,360 --> 00:13:27,900
Polisan obliga a la IA a hacer todo el trabajo pesado de probar que sigue las reglas.

151
00:13:27,900 --> 00:13:33,660
A nosotros o a nuestros sistemas de supervisión solo nos toca hacer la verificación fácil.

152
00:13:34,000 --> 00:13:34,280
Vaya.

153
00:13:35,280 --> 00:13:37,500
Eso invierte la dinámica por completo.

154
00:13:38,140 --> 00:13:42,740
La IA no puede actuar hasta que no demuestre que lo hace de forma segura.

155
00:13:42,740 --> 00:13:43,940
Exacto.

156
00:13:43,940 --> 00:13:46,200
La supervisión se vuelve escalable.

157
00:13:46,780 --> 00:13:48,520
Y luego está la capa final.

158
00:13:49,260 --> 00:13:49,880
Plenum Hub.

159
00:13:50,260 --> 00:13:52,920
Es el tejido que coordina a múltiples sillas.

160
00:13:53,620 --> 00:13:57,080
Un espacio compartido donde las reglas de todos son públicas.

161
00:13:57,480 --> 00:14:02,620
Y una interacción solo se permite si satisface las reglas de todos los implicados a la vez.

162
00:14:02,620 --> 00:14:05,980
A ver, eso suena a que se podría paralizar todo, ¿no?

163
00:14:06,300 --> 00:14:09,660
Si cada acción tiene que satisfacer las reglas de todo el mundo.

164
00:14:10,020 --> 00:14:12,920
Es una duda legítima, pero piensa en una analogía.

165
00:14:13,760 --> 00:14:15,260
El control del tráfico aéreo.

166
00:14:16,000 --> 00:14:21,800
Es un sistema donde cada avión debe seguir reglas estrictas, visibles para todos, para evitar chocar.

167
00:14:22,640 --> 00:14:24,560
Esas reglas no paralizan los viajes.

168
00:14:25,180 --> 00:14:27,700
Al contrario, son las que los hacen posibles.

169
00:14:27,920 --> 00:14:31,480
Son las que los hacen posibles y seguros a gran escala.

170
00:14:31,480 --> 00:14:35,640
Plenum Hub es una versión generalizada de eso.

171
00:14:36,400 --> 00:14:40,500
No impide la acción, sino que previene la tragedia de los comunes,

172
00:14:40,900 --> 00:14:44,120
donde todos terminan destruyendo un recurso compartido.

173
00:14:44,960 --> 00:14:49,540
Aquí, las externalidades negativas están prohibidas por la arquitectura.

174
00:14:50,880 --> 00:14:56,620
Entonces, para unir las piezas, SpherePop o S es la base con memoria.

175
00:14:56,620 --> 00:15:06,000
Polisán es el guardián que exige pruebas y Plenum Hub es la plaza pública donde las IAs interactúan de forma segura.

176
00:15:06,620 --> 00:15:07,780
Esa es la visión completa.

177
00:15:08,460 --> 00:15:11,000
Y por eso lo llaman el camino estrecho.

178
00:15:11,780 --> 00:15:15,520
No es un equilibrio frágil que dependa de que las IAs se porten bien.

179
00:15:15,520 --> 00:15:23,580
Es un camino pavimentado, construido por diseño, que nos protege de la dominación de una IA o del caos de muchas.

180
00:15:23,800 --> 00:15:28,420
Un plan de ingeniería para la gobernanza global de la IA.

181
00:15:29,240 --> 00:15:36,160
El hilo conductor, si entendí bien, es que los problemas de nuestro mundo digital no son de contenido.

182
00:15:36,620 --> 00:15:37,820
Son estructurales.

183
00:15:38,360 --> 00:15:41,220
Son producto de una optimización sin límites.

184
00:15:41,220 --> 00:15:44,400
Y ese es el mensaje final más potente.

185
00:15:44,980 --> 00:15:48,700
La solución no está en moderar más o en tener mejores intenciones.

186
00:15:49,200 --> 00:15:50,820
Tampoco en ir más despacio.

187
00:15:51,480 --> 00:15:54,680
Está en construir sistemas con límites en su arquitectura.

188
00:15:55,440 --> 00:16:00,200
El gran objetivo del alineamiento no debería ser enseñarle a las máquinas qué desear.

189
00:16:00,560 --> 00:16:01,340
Sino…

190
00:16:01,340 --> 00:16:04,860
Sino asegurar que ningún sistema, por inteligente que sea,

191
00:16:04,860 --> 00:16:10,540
pueda anular las condiciones que hacen que la elección humana siga siendo significativa.

192
00:16:11,220 --> 00:16:14,520
Hay una frase que citamos antes y que se me quedó grabada.

193
00:16:15,120 --> 00:16:18,580
El pensamiento sobrevive convirtiéndose en arquitectura.

194
00:16:19,580 --> 00:16:25,600
Los textos dicen que nuestros entornos, desde un archivador a una ciudad, extienden nuestra mente.

195
00:16:26,180 --> 00:16:28,420
Y esto me deja con una última reflexión.

196
00:16:29,140 --> 00:16:34,240
Quizás lo más importante que construiremos este siglo no sea una IA más inteligente.

197
00:16:35,080 --> 00:16:36,220
Sino…

198
00:16:36,220 --> 00:16:40,480
Sino una habitación más sabia para que esa inteligencia pueda vivir.

